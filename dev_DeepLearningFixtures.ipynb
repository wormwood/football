{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from FixturesOdds import FixturesOdds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_pandas.Automater import Automater\n",
    "from keras.layers import Dense\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_pred=FixturesOdds()\n",
    "fix_pred.fix_load('vwCSV_3','vwCSV_3.csv', False) # no reresh\n",
    "fix_pred.do_calcs()\n",
    "fix_pred.clean_predict()\n",
    "X=fix_pred.X()\n",
    "Y=fix_pred.y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data set, using keras_pandas\n",
    "categorical_vars = ['ExpectedResult']\n",
    "numerical_vars = ['FTG_3', 'FTG_5', 'HomeOdds', 'DrawOdds', 'AwayOdds']\n",
    "text_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([304, 331, 379, ..., 310, 499, 345])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_pandas/transformations.py:348: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/keras_pandas/transformations.py:383: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/keras_pandas/constants.py:33: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  transformed = input_dataframe[variable].as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7268 samples, validate on 1817 samples\n",
      "Epoch 1/40\n",
      "7268/7268 [==============================] - 2s 271us/step - loss: 6.1645 - acc: 0.0116 - val_loss: 6.0020 - val_acc: 0.0143\n",
      "Epoch 2/40\n",
      "7268/7268 [==============================] - 2s 224us/step - loss: 5.8834 - acc: 0.0143 - val_loss: 5.9738 - val_acc: 0.0132\n",
      "Epoch 3/40\n",
      "7268/7268 [==============================] - 2s 223us/step - loss: 5.8209 - acc: 0.0142 - val_loss: 5.9682 - val_acc: 0.0160\n",
      "Epoch 4/40\n",
      "7268/7268 [==============================] - 2s 232us/step - loss: 5.7864 - acc: 0.0161 - val_loss: 5.9925 - val_acc: 0.0160\n",
      "Epoch 5/40\n",
      "7268/7268 [==============================] - 2s 290us/step - loss: 5.7604 - acc: 0.0150 - val_loss: 6.0190 - val_acc: 0.0138\n",
      "Epoch 6/40\n",
      "7268/7268 [==============================] - 1s 190us/step - loss: 5.7371 - acc: 0.0142 - val_loss: 6.0591 - val_acc: 0.0154\n",
      "Epoch 7/40\n",
      "7268/7268 [==============================] - 1s 180us/step - loss: 5.7175 - acc: 0.0150 - val_loss: 6.0886 - val_acc: 0.0138\n",
      "Epoch 8/40\n",
      "7268/7268 [==============================] - 2s 250us/step - loss: 5.6977 - acc: 0.0151 - val_loss: 6.1126 - val_acc: 0.0149\n",
      "Epoch 9/40\n",
      "7268/7268 [==============================] - 1s 204us/step - loss: 5.6798 - acc: 0.0133 - val_loss: 6.1359 - val_acc: 0.0121\n",
      "Epoch 10/40\n",
      "7268/7268 [==============================] - 1s 194us/step - loss: 5.6652 - acc: 0.0149 - val_loss: 6.1510 - val_acc: 0.0138\n",
      "Epoch 11/40\n",
      "7268/7268 [==============================] - 2s 254us/step - loss: 5.6485 - acc: 0.0142 - val_loss: 6.1883 - val_acc: 0.0110\n",
      "Epoch 12/40\n",
      "7268/7268 [==============================] - 2s 279us/step - loss: 5.6338 - acc: 0.0157 - val_loss: 6.2075 - val_acc: 0.0127\n",
      "Epoch 13/40\n",
      "7268/7268 [==============================] - 2s 270us/step - loss: 5.6196 - acc: 0.0153 - val_loss: 6.2337 - val_acc: 0.0110\n",
      "Epoch 14/40\n",
      "7268/7268 [==============================] - 1s 186us/step - loss: 5.6065 - acc: 0.0161 - val_loss: 6.2490 - val_acc: 0.0116\n",
      "Epoch 15/40\n",
      "7268/7268 [==============================] - 2s 237us/step - loss: 5.5944 - acc: 0.0153 - val_loss: 6.2702 - val_acc: 0.0110\n",
      "Epoch 16/40\n",
      "7268/7268 [==============================] - 2s 211us/step - loss: 5.5838 - acc: 0.0161 - val_loss: 6.2924 - val_acc: 0.0121\n",
      "Epoch 17/40\n",
      "7268/7268 [==============================] - 2s 231us/step - loss: 5.5735 - acc: 0.0162 - val_loss: 6.3029 - val_acc: 0.0077\n",
      "Epoch 18/40\n",
      "7268/7268 [==============================] - 1s 169us/step - loss: 5.5629 - acc: 0.0169 - val_loss: 6.3270 - val_acc: 0.0110\n",
      "Epoch 19/40\n",
      "7268/7268 [==============================] - 1s 179us/step - loss: 5.5536 - acc: 0.0165 - val_loss: 6.3474 - val_acc: 0.0077\n",
      "Epoch 20/40\n",
      "7268/7268 [==============================] - 1s 169us/step - loss: 5.5471 - acc: 0.0166 - val_loss: 6.3565 - val_acc: 0.0110\n",
      "Epoch 21/40\n",
      "7268/7268 [==============================] - 2s 213us/step - loss: 5.5377 - acc: 0.0173 - val_loss: 6.3686 - val_acc: 0.0088\n",
      "Epoch 22/40\n",
      "7268/7268 [==============================] - 1s 193us/step - loss: 5.5305 - acc: 0.0154 - val_loss: 6.3887 - val_acc: 0.0066\n",
      "Epoch 23/40\n",
      "7268/7268 [==============================] - 1s 146us/step - loss: 5.5235 - acc: 0.0173 - val_loss: 6.3953 - val_acc: 0.0072\n",
      "Epoch 24/40\n",
      "7268/7268 [==============================] - 2s 277us/step - loss: 5.5159 - acc: 0.0169 - val_loss: 6.4137 - val_acc: 0.0083\n",
      "Epoch 25/40\n",
      "7268/7268 [==============================] - 2s 217us/step - loss: 5.5096 - acc: 0.0188 - val_loss: 6.4123 - val_acc: 0.0088\n",
      "Epoch 26/40\n",
      "7268/7268 [==============================] - 1s 178us/step - loss: 5.5012 - acc: 0.0187 - val_loss: 6.4229 - val_acc: 0.0099\n",
      "Epoch 27/40\n",
      "7268/7268 [==============================] - 2s 258us/step - loss: 5.4942 - acc: 0.0187 - val_loss: 6.4512 - val_acc: 0.0094\n",
      "Epoch 28/40\n",
      "7268/7268 [==============================] - 2s 212us/step - loss: 5.4872 - acc: 0.0165 - val_loss: 6.4680 - val_acc: 0.0077\n",
      "Epoch 29/40\n",
      "7268/7268 [==============================] - 1s 165us/step - loss: 5.4811 - acc: 0.0177 - val_loss: 6.4857 - val_acc: 0.0072\n",
      "Epoch 30/40\n",
      "7268/7268 [==============================] - 1s 158us/step - loss: 5.4703 - acc: 0.0190 - val_loss: 6.4840 - val_acc: 0.0061\n",
      "Epoch 31/40\n",
      "7268/7268 [==============================] - 1s 162us/step - loss: 5.4652 - acc: 0.0197 - val_loss: 6.5082 - val_acc: 0.0099\n",
      "Epoch 32/40\n",
      "7268/7268 [==============================] - 1s 143us/step - loss: 5.4579 - acc: 0.0202 - val_loss: 6.5051 - val_acc: 0.0088\n",
      "Epoch 33/40\n",
      "7268/7268 [==============================] - 1s 154us/step - loss: 5.4503 - acc: 0.0193 - val_loss: 6.5255 - val_acc: 0.0094\n",
      "Epoch 34/40\n",
      "7268/7268 [==============================] - 1s 165us/step - loss: 5.4425 - acc: 0.0188 - val_loss: 6.5380 - val_acc: 0.0077\n",
      "Epoch 35/40\n",
      "7268/7268 [==============================] - 1s 160us/step - loss: 5.4350 - acc: 0.0183 - val_loss: 6.5427 - val_acc: 0.0088\n",
      "Epoch 36/40\n",
      "7268/7268 [==============================] - 1s 155us/step - loss: 5.4286 - acc: 0.0198 - val_loss: 6.5476 - val_acc: 0.0088\n",
      "Epoch 37/40\n",
      "7268/7268 [==============================] - 1s 144us/step - loss: 5.4213 - acc: 0.0204 - val_loss: 6.5724 - val_acc: 0.0099\n",
      "Epoch 38/40\n",
      "7268/7268 [==============================] - 1s 143us/step - loss: 5.4144 - acc: 0.0222 - val_loss: 6.5788 - val_acc: 0.0061\n",
      "Epoch 39/40\n",
      "7268/7268 [==============================] - 2s 209us/step - loss: 5.4039 - acc: 0.0206 - val_loss: 6.5752 - val_acc: 0.0083\n",
      "Epoch 40/40\n",
      "7268/7268 [==============================] - 1s 177us/step - loss: 5.4012 - acc: 0.0213 - val_loss: 6.5929 - val_acc: 0.0099\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "auto = Automater(categorical_vars=categorical_vars, numerical_vars=numerical_vars, text_vars=text_vars,\n",
    " response_var='ExpectedResult')\n",
    "X, y = auto.fit_transform(fix_pred.df)\n",
    "\n",
    "# Start model with provided input nub\n",
    "x = auto.input_nub\n",
    "\n",
    "# Fill in your own hidden layers\n",
    "x = Dense(32)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32)(x)\n",
    "\n",
    "# End model with provided output nub\n",
    "x = auto.output_nub(x)\n",
    "\n",
    "model = Model(inputs=auto.input_layers, outputs=x)\n",
    "model.compile(optimizer='Adam', loss=auto.loss, metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X, y, epochs=40, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [6.001955478218931,\n",
       "  5.973792381318113,\n",
       "  5.968228222054968,\n",
       "  5.992473196051708,\n",
       "  6.018993920392891,\n",
       "  6.059069646867869,\n",
       "  6.088551053911628,\n",
       "  6.112585862652574,\n",
       "  6.135863124635367,\n",
       "  6.150988302981387,\n",
       "  6.188325320618062,\n",
       "  6.207511950930069,\n",
       "  6.233692999521192,\n",
       "  6.248984435002228,\n",
       "  6.270189830872405,\n",
       "  6.292374940251806,\n",
       "  6.30293353074976,\n",
       "  6.326972076770822,\n",
       "  6.34739949064197,\n",
       "  6.356511116290263,\n",
       "  6.36857980440525,\n",
       "  6.3886995465137435,\n",
       "  6.395305817509065,\n",
       "  6.413737909047238,\n",
       "  6.4122611902937106,\n",
       "  6.422899805456318,\n",
       "  6.451220616575251,\n",
       "  6.467971476868213,\n",
       "  6.485650224218542,\n",
       "  6.48395622649164,\n",
       "  6.508217106957192,\n",
       "  6.505050625588518,\n",
       "  6.5255057398408205,\n",
       "  6.537954377681919,\n",
       "  6.542705740060003,\n",
       "  6.547607288035182,\n",
       "  6.572371219893242,\n",
       "  6.578801457673295,\n",
       "  6.575195735276369,\n",
       "  6.592901210963365],\n",
       " 'val_acc': [0.014309301045679693,\n",
       "  0.013208585580627407,\n",
       "  0.015960374243258118,\n",
       "  0.015960374243258118,\n",
       "  0.01375894331315355,\n",
       "  0.015410016510731976,\n",
       "  0.01375894331315355,\n",
       "  0.014859658778205834,\n",
       "  0.012107870115575124,\n",
       "  0.01375894331315355,\n",
       "  0.01100715465052284,\n",
       "  0.012658227848101266,\n",
       "  0.01100715465052284,\n",
       "  0.011557512383048982,\n",
       "  0.01100715465052284,\n",
       "  0.012107870115575124,\n",
       "  0.007705008255365988,\n",
       "  0.01100715465052284,\n",
       "  0.007705008255365988,\n",
       "  0.01100715465052284,\n",
       "  0.008805723720418272,\n",
       "  0.006604292790313704,\n",
       "  0.007154650522839846,\n",
       "  0.00825536598789213,\n",
       "  0.008805723720418272,\n",
       "  0.009906439185470555,\n",
       "  0.009356081452944413,\n",
       "  0.007705008255365988,\n",
       "  0.007154650522839846,\n",
       "  0.006053935057787562,\n",
       "  0.009906439185470555,\n",
       "  0.008805723720418272,\n",
       "  0.009356081452944413,\n",
       "  0.007705008255365988,\n",
       "  0.008805723720418272,\n",
       "  0.008805723720418272,\n",
       "  0.009906439185470555,\n",
       "  0.006053935057787562,\n",
       "  0.00825536598789213,\n",
       "  0.009906439185470555],\n",
       " 'loss': [6.1644612867620925,\n",
       "  5.883372421768516,\n",
       "  5.820870156463975,\n",
       "  5.786384139535974,\n",
       "  5.7604430371349045,\n",
       "  5.737129845983981,\n",
       "  5.717489979722438,\n",
       "  5.697697584092388,\n",
       "  5.6798490661805845,\n",
       "  5.665167632179071,\n",
       "  5.648464134123933,\n",
       "  5.633763091014385,\n",
       "  5.619566225651273,\n",
       "  5.606516978211894,\n",
       "  5.594365881246463,\n",
       "  5.583765430114528,\n",
       "  5.573507262772102,\n",
       "  5.562926877640602,\n",
       "  5.5535942785150745,\n",
       "  5.547106820013606,\n",
       "  5.537709980924246,\n",
       "  5.530534209165851,\n",
       "  5.523484295124396,\n",
       "  5.515869645542277,\n",
       "  5.509590178318055,\n",
       "  5.5011817604615,\n",
       "  5.494171903103212,\n",
       "  5.4871850305031336,\n",
       "  5.48105498625147,\n",
       "  5.470341038165935,\n",
       "  5.465191361401589,\n",
       "  5.457857645273077,\n",
       "  5.450311179992978,\n",
       "  5.4424965637492555,\n",
       "  5.435047432558839,\n",
       "  5.428622937294304,\n",
       "  5.421264487829718,\n",
       "  5.414354968608968,\n",
       "  5.40386391919461,\n",
       "  5.401225520151293],\n",
       " 'acc': [0.011557512383048982,\n",
       "  0.014309301045679693,\n",
       "  0.014171711612548156,\n",
       "  0.016097963676389652,\n",
       "  0.014997248211337369,\n",
       "  0.014171711612548156,\n",
       "  0.014997248211337369,\n",
       "  0.015134837644468905,\n",
       "  0.013346175013758944,\n",
       "  0.014859658778205834,\n",
       "  0.014171711612548156,\n",
       "  0.015685195376995045,\n",
       "  0.01527242707760044,\n",
       "  0.016097963676389652,\n",
       "  0.01527242707760044,\n",
       "  0.016097963676389652,\n",
       "  0.016235553109521187,\n",
       "  0.016923500275178867,\n",
       "  0.01651073197578426,\n",
       "  0.016648321408915794,\n",
       "  0.017336268574573474,\n",
       "  0.015410016510731976,\n",
       "  0.017336268574573474,\n",
       "  0.016923500275178867,\n",
       "  0.018849752339020365,\n",
       "  0.018712162905888827,\n",
       "  0.018712162905888827,\n",
       "  0.01651073197578426,\n",
       "  0.017749036873968078,\n",
       "  0.0189873417721519,\n",
       "  0.019675288937809576,\n",
       "  0.020225646670335717,\n",
       "  0.01926252063841497,\n",
       "  0.018849752339020365,\n",
       "  0.018299394606494223,\n",
       "  0.01981287837094111,\n",
       "  0.020363236103467255,\n",
       "  0.022151898734177215,\n",
       "  0.020638414969730325,\n",
       "  0.021326362135388]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
